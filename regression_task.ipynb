{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "l7WDl6TE4UmA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77aebe9d-0fc2-4934-b143-27c87b18d20c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import re\n",
        "import lightgbm as lgb\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import json\n",
        "import gzip\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training data from files\n",
        "train_classification_df = pd.read_csv(\"/content/train-classification.csv\")\n",
        "train_classification_df = train_classification_df.rename(columns={'Unnamed: 0': 'user_id', 'label': 'category'})\n",
        "\n",
        "# Unify labels to lowercase\n",
        "train_classification_df[\"category\"] = train_classification_df[\"category\"].apply(str.lower)\n",
        "username2_category = train_classification_df.set_index(\"user_id\").to_dict()[\"category\"]\n",
        "\n",
        "# Load training dataset\n",
        "# Load training data\n",
        "train_data_path = \"/content/drive/MyDrive/released_dataset/training-dataset.jsonl.gz\"\n",
        "\n",
        "username2posts_train = dict()\n",
        "username2profile_train = dict()\n",
        "username2posts_test = dict()\n",
        "username2profile_test = dict()\n",
        "\n",
        "# Continuing with data loading\n",
        "with gzip.open(train_data_path, \"rt\") as fh:\n",
        "   for line in fh:\n",
        "       sample = json.loads(line)\n",
        "       profile = sample[\"profile\"]\n",
        "       username = profile[\"username\"]\n",
        "\n",
        "       if username in username2_category:\n",
        "           username2posts_train[username] = sample[\"posts\"]\n",
        "           username2profile_train[username] = profile\n",
        "       else:\n",
        "           username2posts_test[username] = sample[\"posts\"]\n",
        "           username2profile_test[username] = profile\n",
        "\n"
      ],
      "metadata": {
        "id": "QO2H2ABzCv2h"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-8wHaR1Bt2k",
        "outputId": "9bf94ff2-9cc0-49ca-8e1c-d7deaf405fa3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First, let's just try a simple prediction approach\n",
        "def extract_basic_features(post, username, username2posts_train):\n",
        "    # Get historical posts for this user from training data\n",
        "    historical_posts = username2posts_train.get(username, [])\n",
        "\n",
        "    # Calculate basic user statistics\n",
        "    historical_likes = [p.get('like_count', 0) or 0 for p in historical_posts]\n",
        "\n",
        "    if historical_likes:\n",
        "        median_likes = np.median(historical_likes)\n",
        "        mean_likes = np.mean(historical_likes)\n",
        "        std_likes = np.std(historical_likes) if len(historical_likes) > 1 else 1\n",
        "    else:\n",
        "        # If no historical data, use global statistics\n",
        "        all_likes = []\n",
        "        for posts in username2posts_train.values():\n",
        "            all_likes.extend([p.get('like_count', 0) or 0 for p in posts])\n",
        "        median_likes = np.median(all_likes)\n",
        "        mean_likes = np.mean(all_likes)\n",
        "        std_likes = np.std(all_likes)\n",
        "\n",
        "    features = {\n",
        "        'user_median_likes': median_likes,\n",
        "        'user_mean_likes': mean_likes,\n",
        "        'user_std_likes': std_likes,\n",
        "        'comment_count': post.get('comments_count', 0) or 0,\n",
        "        'caption_length': len(post.get('caption', '') or ''),\n",
        "        'media_type': post.get('media_type', 'unknown')\n",
        "    }\n",
        "\n",
        "    return features\n"
      ],
      "metadata": {
        "id": "Behajmivqm4n"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(username2posts_train):\n",
        "    # Prepare training data\n",
        "    print(\"Preparing training data...\")\n",
        "    train_features = []\n",
        "    train_targets = []\n",
        "\n",
        "    for username, posts in username2posts_train.items():\n",
        "        for post in posts:\n",
        "            features = extract_basic_features(post, username, username2posts_train)\n",
        "            train_features.append(features)\n",
        "            train_targets.append(post.get('like_count', 0) or 0)\n",
        "\n",
        "    X = pd.DataFrame(train_features)\n",
        "    y = np.array(train_targets)\n",
        "\n",
        "    # Handle categorical variables\n",
        "    le = LabelEncoder()\n",
        "    all_media_types = list(X['media_type'].unique())\n",
        "    if 'unknown' not in all_media_types:\n",
        "        all_media_types.append('unknown')\n",
        "    le.fit(all_media_types)\n",
        "    X['media_type'] = le.transform(X['media_type'])\n",
        "\n",
        "    # Scale numerical features\n",
        "    numerical_features = [col for col in X.columns if col != 'media_type']\n",
        "    scaler = StandardScaler()\n",
        "    X[numerical_features] = scaler.fit_transform(X[numerical_features])\n",
        "\n",
        "    # Log transform target\n",
        "    y_log = np.log10(y + 1)\n",
        "\n",
        "    # Model\n",
        "    model = lgb.LGBMRegressor(\n",
        "        objective='regression',\n",
        "        n_estimators=500,\n",
        "        learning_rate=0.05,\n",
        "        num_leaves=63,\n",
        "        feature_fraction=0.9,\n",
        "        subsample=0.8,\n",
        "        min_child_samples=20,\n",
        "        reg_alpha=0.1,\n",
        "        reg_lambda=0.1,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        verbose=-1\n",
        "    )\n",
        "\n",
        "    print(\"Training model...\")\n",
        "    model.fit(X, y_log)\n",
        "\n",
        "    return model, scaler, le, numerical_features\n"
      ],
      "metadata": {
        "id": "tSyVBjoMC5wJ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_batch(model, scaler, le, numerical_features, username2posts):\n",
        "    X_test, y_true = extract_basic_features(username2posts)\n",
        "\n",
        "    # Transform features\n",
        "    X_test['media_type'] = le.transform(X_test['media_type'])\n",
        "    X_test[numerical_features] = scaler.transform(X_test[numerical_features])\n",
        "\n",
        "    # Predict and ensure no negative values\n",
        "    y_pred_log = model.predict(X_test)\n",
        "    y_pred = np.expm1(y_pred_log)\n",
        "\n",
        "    # Post-process predictions\n",
        "    y_pred = np.maximum(0, y_pred)  # Ensure no negative values\n",
        "\n",
        "    # Handle very low predictions as potential zeros\n",
        "    zero_threshold = 0.5\n",
        "    y_pred[y_pred < zero_threshold] = 0\n",
        "\n",
        "    return y_pred, y_true\n",
        "\n"
      ],
      "metadata": {
        "id": "dpFXSwxBC5yN"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_mse_like_counts(y_true, y_pred):\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    print(\"Min true value:\", np.min(y_true))\n",
        "    print(\"Max true value:\", np.max(y_true))\n",
        "    print(\"Min pred value:\", np.min(y_pred))\n",
        "    print(\"Max pred value:\", np.max(y_pred))\n",
        "    print(\"Number of zeros in true:\", np.sum(y_true == 0))\n",
        "    print(\"Number of zeros in pred:\", np.sum(y_pred == 0))\n",
        "\n",
        "    log_y_true = np.log10(y_true + 1)  # Add 1 to handle zeros\n",
        "    log_y_pred = np.log10(y_pred + 1)  # Add 1 to handle zeros\n",
        "\n",
        "    return np.mean((log_y_true - log_y_pred) ** 2)"
      ],
      "metadata": {
        "id": "t45lZQBRC50i"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data and train model\n",
        "print(\"Training model...\")\n",
        "model, scaler, le, numerical_features = train_model(username2posts_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4PtqnyCC53B",
        "outputId": "8c727ab0-e678-4bff-a549-02ef201f6879"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model...\n",
            "Preparing training data...\n",
            "Training model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate training performance\n",
        "print(\"\\nEvaluating training performance...\")\n",
        "train_features = []\n",
        "train_targets = []\n",
        "\n",
        "for username, posts in username2posts_train.items():\n",
        "    for post in posts:\n",
        "        features = extract_basic_features(post, username, username2posts_train)\n",
        "        train_features.append(features)\n",
        "        train_targets.append(post.get('like_count', 0) or 0)\n",
        "\n",
        "X_train = pd.DataFrame(train_features)\n",
        "X_train['media_type'] = le.transform(X_train['media_type'])\n",
        "X_train[numerical_features] = scaler.transform(X_train[numerical_features])\n",
        "\n",
        "y_train_pred_log = model.predict(X_train)\n",
        "y_train_pred = np.power(10, y_train_pred_log) - 1\n",
        "y_train_pred = np.maximum(0, y_train_pred)\n",
        "\n",
        "train_score = log_mse_like_counts(train_targets, y_train_pred)\n",
        "print(f\"Training Log MSE: {train_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aYd164cMcez",
        "outputId": "bc6e7e68-e220-474e-f60f-a014f267bc0e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating training performance...\n",
            "Min true value: 0.0\n",
            "Max true value: 4246897.0\n",
            "Min pred value: 0.0\n",
            "Max pred value: 1327989.5824801642\n",
            "Number of zeros in true: 3745\n",
            "Number of zeros in pred: 534\n",
            "Training Log MSE: 0.07845384875325681\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read and process test data\n",
        "\n",
        "#@title Test Dataset\n",
        "path = \"/content/test-regression-round3.jsonl\"\n",
        "output_path = \"/content/prediction-regression-round.json\"\n",
        "\n",
        "test_data = []\n",
        "test_features = []\n",
        "\n",
        "print(\"\\nProcessing test data...\")\n",
        "with open(path, \"rt\") as fh:\n",
        "    for line in fh:\n",
        "        post = json.loads(line)\n",
        "        test_data.append(post)\n",
        "        features = extract_basic_features(post, post['username'], username2posts_train)\n",
        "        test_features.append(features)\n",
        "\n",
        "print(\"\\nFeature statistics before scaling:\")\n",
        "print(pd.DataFrame(test_features).describe())\n",
        "\n",
        "# Convert to DataFrame and transform features\n",
        "X_test = pd.DataFrame(test_features)\n",
        "X_test['media_type'] = le.transform(X_test['media_type'])\n",
        "X_test[numerical_features] = scaler.transform(X_test[numerical_features])\n",
        "\n",
        "print(\"\\nFeature statistics after scaling:\")\n",
        "print(X_test.describe())\n",
        "\n",
        "# Make predictions\n",
        "y_pred_log = model.predict(X_test)\n",
        "y_pred = np.power(10, y_pred_log) - 1\n",
        "y_pred = np.maximum(0, y_pred)\n",
        "\n",
        "predictions = []\n",
        "for post, pred in zip(test_data, y_pred):\n",
        "    predictions.append({\n",
        "        \"id\": post[\"id\"],\n",
        "        \"username\": post[\"username\"],\n",
        "        \"like_count\": int(pred)\n",
        "    })\n",
        "\n",
        "with open(output_path, \"wt\") as of:\n",
        "    of.write(\"[\\n\")\n",
        "    for i, pred in enumerate(predictions):\n",
        "        
        "        of.write(\"  {\\n\")  # Open object with 2 spaces indent\n",
        "        of.write(f'    \"id\": \"{pred[\"id\"]}\",\\n')\n",
        "        of.write(f'    \"username\": \"{pred[\"username\"]}\",\\n')\n",
        "        of.write(f'    \"like_count\": {pred[\"like_count\"]}\\n')  # No comma after last item\n",
        "        of.write(\"  }\")  # Close object with 2 spaces indent\n",
        "\n",
        "        # Add comma and newline for all but the last item\n",
        "        if i < len(predictions) - 1:\n",
        "            of.write(\",\\n\")\n",
        "        else:\n",
        "            of.write(\"\\n\")\n",
        "\n",
        "    of.write(\"]\\n\")  # End array\n",
        "\n",
        "print(\"Done!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWbJvULtMchV",
        "outputId": "bbe45a57-509a-4561-9275-3da644342fea"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing test data...\n",
            "\n",
            "Feature statistics before scaling:\n",
            "       user_median_likes  user_mean_likes  user_std_likes  comment_count  \\\n",
            "count        3000.000000      3000.000000     3000.000000    3000.000000   \n",
            "mean         2623.132833      6131.153860    24306.333026      87.065667   \n",
            "std         22282.271194     25307.478963    26420.180346     751.826755   \n",
            "min             0.000000         0.000000        0.000000       0.000000   \n",
            "25%            56.750000        77.614286       54.008862       0.000000   \n",
            "50%            61.000000      5840.381602    43763.476046       1.000000   \n",
            "75%            61.000000      5840.381602    43763.476046       8.000000   \n",
            "max        762120.000000    882625.171429   479962.962664   26433.000000   \n",
            "\n",
            "       caption_length  \n",
            "count     3000.000000  \n",
            "mean       297.234000  \n",
            "std        329.229836  \n",
            "min          0.000000  \n",
            "25%         90.000000  \n",
            "50%        203.000000  \n",
            "75%        379.000000  \n",
            "max       2197.000000  \n",
            "\n",
            "Feature statistics after scaling:\n",
            "       user_median_likes  user_mean_likes  user_std_likes  comment_count  \\\n",
            "count        3000.000000      3000.000000     3000.000000    3000.000000   \n",
            "mean           -0.066964         0.008429        0.733572      -0.005005   \n",
            "std             0.724120         0.733637        0.997531       0.221263   \n",
            "min            -0.152210        -0.169306       -0.184148      -0.030629   \n",
            "25%            -0.150365        -0.167056       -0.182108      -0.030629   \n",
            "50%            -0.150227         0.000000        1.468204      -0.030335   \n",
            "75%            -0.150227         0.000000        1.468204      -0.028274   \n",
            "max            24.614837        25.417058       17.937526       7.748630   \n",
            "\n",
            "       caption_length   media_type  \n",
            "count     3000.000000  3000.000000  \n",
            "mean         0.051708     1.118000  \n",
            "std          1.074044     0.710571  \n",
            "min         -0.917956     0.000000  \n",
            "25%         -0.624350     1.000000  \n",
            "50%         -0.255711     1.000000  \n",
            "75%          0.318453     2.000000  \n",
            "max          6.249301     2.000000  \n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print prediction statistics\n",
        "print(\"\\nPrediction Statistics:\")\n",
        "print(f\"Number of predictions: {len(y_pred)}\")\n",
        "print(f\"Mean prediction: {np.mean(y_pred):.2f}\")\n",
        "print(f\"Median prediction: {np.median(y_pred):.2f}\")\n",
        "print(f\"Number of zeros: {np.sum(y_pred == 0)}\")\n",
        "print(f\"Max prediction: {np.max(y_pred):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SokwosAWM8aQ",
        "outputId": "26918fa7-0d29-4a8a-9fbd-75b49e221782"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prediction Statistics:\n",
            "Number of predictions: 3000\n",
            "Mean prediction: 2976.77\n",
            "Median prediction: 36.46\n",
            "Number of zeros: 7\n",
            "Max prediction: 768326.54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "41X2v8gqMcjh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
